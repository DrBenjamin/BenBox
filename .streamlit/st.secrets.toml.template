# LLM Provider
LLM_LOCAL = "False"  # `False` for local Ollama model, `True` for OpenAI API

# Storage Settings
USE_SNOWFLAKE = "True"  # Use Snowflake for file storage instead of local filesystem

# MCP API
[MCP]
MCP_URL = "http://127.0.0.1:8080"
MCP_SYSTEM_PROMPT = "<system prompt for image recognition>"
MCP_USER_PROMPT = "<user prompt for image recognition>"

# Ollama API
[OLLAMA]
OLLAMA_URL = "http://127.0.0.1:11434"
OLLAMA_MODEL = "<ollama model>" # e.g. llava or "llama3.2-vision"

# Azure OpenAI API
[AZURE_OPENAI]
AZURE_OPENAI_API_KEY = "<your-azure-openai-api-key>"
AZURE_OPENAI_ENDPOINT = "<your-azure-openai-endpoint>"
AZURE_OPENAI_MODEL = "<your-azure-openai-model>" # e.g. gpt-4.1
AZURE_OPENAI_API_VERSION = "<your-api-version>" # e.g. 2024-02-15-preview

# Snowflake Configuration
[SNOWFLAKE]
ACCOUNT = "<your-snowflake-account>"
USER = "<your-snowflake-username>"
PASSWORD = "<your-snowflake-password>"
WAREHOUSE = "<your-snowflake-warehouse>"
DATABASE = "<your-snowflake-database>"
SCHEMA = "<your-snowflake-schema>"
STAGE = "<your-snowflake-stage-name>"